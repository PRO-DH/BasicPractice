#------------------- Day 16----------------------   

print("\n\n\n\n\n\n 06.29. \n\n\n\n\n\n")       #라이브러리 다루기, 크롤링-

# 네트워크란 ? = 데이터를 주고 받는것
# client 데이터를 요청하는 주체
# server 데이터를 제공하는 주체
# request 데이터를 요청하는 행위
# response 데이터를 제공하는 행위

# 웹 브라우저 - chrome edge safari firefox ...
# 웹 크롤링 : 웹에서 데이터 따오는 것
# HTML의 3가지
# 1. 태그 = <가 나와서 공백까지를 ~태그 라고 한다.
# ex) <div asdgad   - div태그
# <ul asdgadg  - ul태그
# <>여는 태그 </>닫는 태그
# 2. 속성 = 태그 뒤의 값들
# ex) <em class="theme category" </em>  -->> 속성값 : class = theme category
# 3. 텍스트 = <>에 쌓여있지 않은 부분, 외부로 노출 !  

# <1> requests
# import requests
# res = requests.get(url)
# res 는 response 클래스의 인스턴스 - res.text(html소스)
from this import s
import requests
res = requests.get("https://www.naver.com")
# <2>
# res.text는 파이썬에서 아무 의미 없기 때문에 파싱을 해준다. 이떄 필요한게 beautifusoup
# beautifulsoup(A,B) A 에는 아무 의미 없는 문자열, B에는 문법
# 파싱(parsing) : 규격에 맞춰서 해석함
from bs4 import BeautifulSoup       # BeautifulSoup - Class이다.
soup = BeautifulSoup(res.text,"html.parser")
# 아무 의미없는 res.text(HTML소스)를 HTML 형식으로 해석할수 있는 soup 생성
# <3>
# soup.select(셀렉터) > 반환값 : 태그들
# soup.sewlect_one(셀렉터) > 반환값 : 태그하나
# 셀렉터 : 태그를 지칭하는 방법
# -- 1) 태그는 그래도
# -- 2) id는 #
# -- 3) class 는 .
# -- 4) 하위태그는 >
st = """
<html id="a">
    <body class="b">
        <div id="hello1">안녕1</div>
        <div class="hello2">안녕2</div>
        <div>
            <span id="jeju" class="busan">안녕3</span>
        </div>
        <a id="seoul" class"daegu" href="https://www.naver.com">NAVER</a>
    </body>
</html>
"""
soup = BeautifulSoup(st,"html.parser")
print(soup.select("#jeju"))
print(soup.select(".busan"))
print(soup.select("html>div>span"))
print(soup.select_one("div"))

# 예제 1. 네이버웹툰 참교육 평점 가져오기
from bs4 import BeautifulSoup
import requests
res = requests.get("https://comic.naver.com/webtoon/detail?titleId=758037&no=86&weekday=mon")
soup = BeautifulSoup(res.text,"html.parser")
print(soup.select("#topPointTotalNumber > strong"))
print(soup.select(".pointTotalPerson > em"))

# <4> 태그 클래스의 매서드/필드
# soup.select 반환값 : tag 클래스의 인스턴스들의 리스트
# soup.select_one 반환값 : tag 클래스의 인스턴스
# --1) text : 텍스트 부분 추출
# 텍스트 추출하기(리스트말고 인스턴스에 접근해야함)
import requests
from bs4 import BeautifulSoup
res = requests.get("https://comic.naver.com/webtoon/detail?titleId=758037&no=86")
soup = BeautifulSoup(res.text, "html.parser")
print( soup.select_one(".view > h3").text)
print( soup.select_one("#topPointTotalNumber > strong").text )
print(  soup.select_one(".pointTotalPerson > em").text )
print( soup.select_one(".date").text )

# 데이터 전송방식
# --1) GET  : url을 통해서 데이터 전송
#   - ? : 데이터 전송의 시작
#   - & : 데이터 연결
#   - 민감데이터 전송에는 부적절(ex 로그인) 
#   - 데이터 
# --2) POST : 숨겨서 전송

# 참교육 웹툰 1~86화 제목/평점/참여자수/날짜 엑셀에 담기
f = open("참교육.csv","w")
import requests
from bs4 import BeautifulSoup
for k in range(1,87):
    res = requests.get(f"https://comic.naver.com/webtoon/detail?titleId=758037&no={k}")
    soup = BeautifulSoup(res.text, "html.parser")
    제목 = ( soup.select_one(".view > h3").text)
    평점 = ( soup.select_one("#topPointTotalNumber > strong").text )
    참여자수 = (  soup.select_one(".pointTotalPerson > em").text )
    날짜 = ( soup.select_one(".date").text )
    f.write(f"{제목},{평점},{참여자수},{날짜}")








#------------------- Day 17----------------------   

print("\n\n\n\n\n\n 06.30. \n\n\n\n\n\n")       # 크롤링 다루기


# 태그 클래스의 매서드필드
# 1. .text          > 텍스트 부분 추출
# 2. .get(속성명)   > 속성값 추출
# 3. .select()      > 마저자르기
#    .select_one()

# res.text > HTML 소스
# res.content > 바이너리 (동영상 사진)
# 2.파싱 BeautifulSoup (아무의미없는 문자열, "html.parser")
# 3.셀렉터 (태그를 지칭하는 방법) 태그 그대로, id# class. 하위태그>
# soup.select() : 태그 클래스 인스턴스들의 리스트
# soup.select_one() : 태그 클래스 
# front - end
# 1. HTML(뼈대) , 2. CSS(꾸며줌)>셀렉터가 핵심(태그지침방법), 3. JAVASCRIPT

# 실습예제 1 ) 뉴스기사의 제목 가져오기
import requests
from bs4 import BeautifulSoup
for k in range(1,11) :
    res = requests.get(f"https://news.ycombinator.com/news?p={k}")
    soup = BeautifulSoup(res.text,"html.parser")
    for i in soup.select(".titlelink") : 
        print(i.text)

# 텍스트 파일 : 텍스트로 해석
# 바이너리 파일 : 텍스트로 해석 X
#   ex) 사진 동영상 압축파일 pdf exe 등등...

# 실습예제 2 ) 바이너리 파일인 사진을 가져와서 바이너리 파일로서 사진 저장하기
import requests
res = requests.get("https://search.pstatic.net/common/?src=http%3A%2F%2Fcafefiles.naver.net%2F20120227_139%2Fmighty_pro_1330350486543XDkBX_JPEG%2F23906050_480mw.jpeg&type=a340")
f = open("kennen.png","wb")     # 바이너리파일로 생성할떈 w가 아닌 wb로 써줘야한다
f.write(res.content)
# image 의 src속성값을 가져와서 다운받으면된다.

# 같은방법으로 동영상 -  동영상은 링크를 보통 숨겨두기 때문에 되는 것이 있고 안되는 것이 있다.

# 속성가져오기
from bs4 import BeautifulSoup
st = """
<html>
    <body>
        <div id="hello1" a="b">안녕1</div>
        <div class="hello2" c="d">안녕2</div>
        <div>
            <span loca="jeju">안녕3</span>
        </div>
        <a href="https://www.naver.com">NAVER</a>
    </body>
</html>"""
soup = BeautifulSoup(st, "html.parser")
# 크롤링의 이유 - text를 가져오거나 속성값을 가져오거나.
print(soup.select_one("span").get("loca"))

# 웹툰 사진들 가져오서 저장하기
import requests
from bs4 import BeautifulSoup 
def 필터(st) :                                                  # 제목에 특수문자 들어간 것들 필터링으로 걸러주기
    for i in '/\:?*"<>|' :
        st = st.replace(i,"")
    return st
res = requests.get("https://comic.naver.com/webtoon/weekday")   # 웹툰 전체 링크
soup = BeautifulSoup(res.text,"html.parser")                    # 링크 내의 코드들을 text로 변환
for i in soup.select(".thumb > a > img") :                      # thumb클래스 하위 a 하위 img로 감
    제목 = (i.get("alt")  )                                     # 속성값이 alt인 것을 제목으로 저장
    썸네일사진 = i.get("src")                                   # 속성값이 src인 것들을 썸넬사진으로 저장
    r = requests.get(썸네일사진)                                # 썸네일 사진(링크)들을 저장
    f = open(f"웹툰/{제목}.png","wb")
    f.write(r.content)                                          # 링크의 내용 쓰기

# 폴더생성 하는 법
import os
def 폴더생성(st) :
    if os.path.isdir(st):
        pass
    else :
        os.mkdir(st)
폴더생성("jeju")

# 폴더생성하여 웹툰 사진들 안에 넣기
import os
def 폴더생성(st) :
    if os.path.isdir(st):
        pass
    else :
        os.mkdir(st)
for k in ['mon','tue','wed','thu','fri','sat','sun'] :
    폴더생성(f"webtoon/{k}")
    import requests
    from bs4 import BeautifulSoup 
    def 필터(st) :                                                  # 제목에 특수문자 들어간 것들 필터링으로 걸러주기
        for i in '/\:?*"<>|' :
            st = st.replace(i,"")
        return st
    res = requests.get(f"https://comic.naver.com/webtoon/weekdayList?week={k}")   # 웹툰 전체 링크
    soup = BeautifulSoup(res.text,"html.parser")                    # 링크 내의 코드들을 text로 변환
    for i in soup.select(".thumb > a > img") :                      # thumb클래스 하위 a 하위 img로 감
        제목 = 필터((i.get("alt")  )          )                     # 속성값이 alt인 것을 제목으로 저장
        썸네일사진 = i.get("src")                                   # 속성값이 src인 것들을 썸넬사진으로 저장
        r = requests.get(썸네일사진)                                # 썸네일 사진(링크)들을 저장
        f = open(f"webtoon/{k}/{제목}.png","wb")
        f.write(r.content)   

# 실습예제
from bs4 import BeautifulSoup
st = """<html>
    <body>
        <div id="champ">
            <span class="name">KENNEN</span>
            <span class="hp">600</span>
            <span class="mp">0</span>
        </div>
        <div id="champ">
            <span class="name">TEEMO</span>
            <span class="hp">400</span>
            <span class="mp">400</span>
        </div>
        <div id="champ">
            <span class="name">VEIGAR</span>
            <span class="hp">300</span>
            <span class="mp">500</span>
        </div>
    </body>
</html>"""
# names = []
soup = BeautifulSoup(st,"html.parser")
# for i in soup.select(".name"):
#     names.append(i.text)
# print(names)
for i in soup.select("#champ") :
    print(i.select_one(".name").text)
    print(i.select_one(".hp").text)
    print(i.select_one(".mp").text)

# 실습 / 영화에서 제목평점 등 가져오기
import requests
from bs4 import BeautifulSoup
res = requests.get("https://search.naver.com/search.naver?sm=tab_hty.top&where=nexearch&query=%EC%98%81%ED%99%94&oquery=%EB%B0%95%EC%8A%A4%EC%98%A4%ED%94%BC%EC%8A%A4top10&tqi=hr0aSwprvmsss7cpbf4ssssstTV-446491")
soup = BeautifulSoup(res.text,"html.parser")
for i in soup.select(".data_box")   :
    영화제목 = i.select_one(".area_text_box > a").text
    평점 = i.select_one(".num").text
    A = i.select(".info_group")
    # 첫번째 info 에는 상영시간, 장르를 가지고 있다.
    B = A[0].select("dd")
    장르 = B[0].text
    상영시간 = B[1].text
    개봉날짜 = A[1].select_one("dd").text
    출연 = A[2].select_one("dd").text
    print(f"영화제목={영화제목}\n평점={평점}\t 장르={장르}\t 상영시간={상영시간}\n개봉날짜 = {개봉날짜}\t출연진={출연}")

# 브라우저 동반하는 라이브러리
# selenium
# 준비물
# - chromedriver.exe
# - pip install selenium

from selenium import webdriver
driver = webdriver.Chrome("chromedriver.exe")
driver.get("https://www.naver.com")             # 이동하기
네이버검색창 = driver.find_element_by_css_selector("#query")
네이버검색창.send_keys("악동뮤지션")
# 검색버튼 = 
# 검색버튼.click
# selenium으로 할수있는 것
#   태그지정하고 나서 할수 있는 행동
#       1. 값을전달 >  send_keys
#       2. 클릭 > click()
input()

# selenium 이용 실습

from selenium import webdriver
driver = webdriver.Chrome("chromedriver.exe")
driver.get("https://www.naver.com")
# 태그 지정하고 나서 할수있는 행동!!
# 1) 값을 전달 >  send_keys(x)
# 2) 클릭 >   click()
네이버검색창 = driver.find_element_by_css_selector("#query")
네이버검색창.send_keys("악동뮤지션")
검색버튼 = driver.find_element_by_css_selector("#search_btn")
검색버튼.click()
이미지버튼 = driver.find_element_by_css_selector("#lnb > div.lnb_group > div > ul > li:nth-child(2) > a")
이미지버튼.click()
input()












#------------------- Day 18----------------------   

print("\n\n\n\n\n\n 07.01. \n\n\n\n\n\n")       # 크롤링 실습

# 웹 크롤링 : 정적크롤링, 동적크롤링(추가적인 동작 필요)

# 1-1. HTML 소스 가져오기 (정적크롤링)
#   - res = requests.get(url)
#   - res.text(html소스), res.content(바이너리값)
# 1-2. HTMl 소스 가져오기 (동적크롤링)
#   - selenium으로 가져와야한다. 
# driver = web
# sleep(3) 
# ht = dirver.page_source
# 2. 파싱 ( 통역가 생성 )
# 3. 셀렉터
# 4. 태그 class

# 실습 1. 롤 인벤에서 이미지 가져오기(동적크롤링)
from selenium import webdriver
from time import sleep
from bs4 import BeautifulSoup
import requests
driver = webdriver.Chrome("chromedriver.exe")
driver.get("https://lol.inven.co.kr/dataninfo/champion/")
sleep(3)
ht = driver.page_source
soup = BeautifulSoup(ht,"html.parser")
def 필터 (st):
    for i in "/\\<>|\"*?" :
        st = st.replace(i,"")
    return st
for i in soup.select(".champImage > a") :
    챔피언이름 =  필터(i.get("title"))
    챔피언링크 =  "https:" + i.select_one("img").get("src")
    res = requests.get(챔피언링크)
    f = open(f"lolicon/{챔피언이름}.png","wb")
    f.write(res.content)

# 실습 2. 포켓몬 사진들 가져오기
from selenium import webdriver
from time import sleep
from bs4 import BeautifulSoup
import requests
driver = webdriver.Chrome("chromedriver.exe")
driver.get("https://pokemongo.inven.co.kr/dataninfo/pokemon/")
sleep(3)
ht = driver.page_source
soup = BeautifulSoup(ht,"html.parser")
def 필터 (st) :
    for i in "/\\<>|?*\"" :
        st = st.replace(i,"")
    return st
for i in soup.select(".pokemonList>li>a") :
    포켓몬이름 = i.select_one(".pokemonname").text
    포켓몬링크 = "https:" + i.select_one("img").get("src")
    res = requests.get(포켓몬링크)
    f = open(f"포켓몬/{포켓몬이름}.png","wb")
    f.write(res.content)

# 파일의 내용들 글자수 가져오기
import os 
# os.listdir(x)
# x 아래의 파일 및 폴더들의 이름들이 리스트로 반환됨
# x의  default값은 현재경로
k = 0
for i in os.listdir("실습") :
    f = open(f"실습/{i}","r",encoding="utf-8")
    k = len(f.read())
    print(k)

# pillow 함수의 image
# img = Image.open("")
# print(img.size)                  # 가로세로 픽셀 수 반환
# print(img.mode)                  # 색상모드 - RGB / RGBA (A는 투명도)
# img = img.resize((500,500))      # 확대/축소
# img.show()                       # img 의 현재상태 보여줌
# img.save("")

# 실습 : 포켓몬 사진들 확대하여 저장하기
from PIL import Image
import os
for i in os.listdir("포켓몬")   :
    img = Image.open(f"포켓몬/{i}")
    img = img.resize((500,500))      
    img.save(f"포켓몬 500/확대{i}.png")


# 실습 : 포켓몬 사진들 중 색 있는 부분은 검게 칠하여 shadow 에 저장하기


# 실습 : shadow로 된 사진들로 포켓몬맞추기 문제내기
import os
from random import randint as ri
from PIL import ImageTk
import tkinter as tk
from tkinter import messagebox

window = tk.Tk()
window.geometry("500x900")
window.title("뭘까요?")
window.resizable(False, False)

score = 0
life = 5
포켓몬목록 = os.listdir("shadow")

la = tk.Label(window)
la.pack()

lalife = tk.Label(window, font=("맑은고딕", 30, "bold"), fg="red")
lalife.pack()

보기인덱스 = set()

def 문제출제():
    global 정답인덱스, 보기인덱스
    정답인덱스 = ri(0, len(포켓몬목록)-1)
    img = ImageTk.PhotoImage(file=f"shadow/{포켓몬목록[정답인덱스]}")
    la["image"] = img
    la.image = img
    보기인덱스 = set()
    보기인덱스.add(정답인덱스)

    while True:
        보기인덱스.add(ri(0, len(포켓몬목록)-1))
        if len(보기인덱스) == 5:
            break
    보기인덱스 = list(보기인덱스)

    for i in range(5):
        button[i]["text"] = 포켓몬목록[보기인덱스[i]].split(".")[1].strip()
    
    lalife["text"] = "♥ "*life + "♡ "* (5-life)

def 채점(idx):
    global 정답인덱스, 보기인덱스, score, life
    
    if 보기인덱스[idx] == 정답인덱스:
        score += 100
        img = ImageTk.PhotoImage(file=f"poke500/{포켓몬목록[정답인덱스]}")
        la["image"] = img
        la.image = img
        messagebox.showinfo("CORRECT!!", "정답입니다.")
        문제출제()
    else:
        life -= 1
        if life == 0:
            messagebox.showinfo("GAME OVER", f"당신의 점수는 {score} 입니다.")
            exit()
    lalife["text"] = "♥ "*life + "♡ "* (5-life)
    
button = [None]*5
for i in range(5):
    button[i] = tk.Button(window, command=lambda x=i:채점(x), width=20, font=("맑은고딕", 20, "bold"), fg="blue")
    button[i].pack()

문제출제()

window.mainloop()


# 실습 : 흑백사진 만들기 - rgb값 전부 더한다음 /3 하여 각각 rgb에 넣어주기
